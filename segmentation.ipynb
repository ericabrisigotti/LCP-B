{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e64715a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import fftpack, stats, signal\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.linalg as la\n",
    "from scipy import signal\n",
    "import pywt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30cff26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def segmentation(ann):\n",
    "# function that performs segmentation based on the relative known proportions between RR, PR and QT \n",
    "# the function returns\n",
    "    \n",
    "    # I initialize the variables I need for the while loop\n",
    "    patient_start = np.ones(2)*-3\n",
    "    i = 1\n",
    "    j = -1\n",
    "    while patient_start[0]<0:\n",
    "        j += 1\n",
    "        # I calculate the RR intervals\n",
    "        RR_intervals = (ann[(j+i):]-ann[j:-i])\n",
    "        # firstly, I crop the RR interval to match the relative proportion of RR:QT=0.8:0.41 \n",
    "        QT_size = (RR_intervals*0.41/0.8).astype(int)\n",
    "        PR_size = (RR_intervals*0.16/0.8).astype(int)\n",
    "        patient_start = ann[j:-i] - PR_size\n",
    "        patient_end = ann[j:-i] + QT_size\n",
    "    # j is the number of annotations ignored from the beginning\n",
    "    # i is the number of annotations ignored from the end\n",
    "    # so that, for compatibility purposes, I will refer to\n",
    "    return QT_size, PR_size, patient_start, patient_end, i, j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82b04233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the algorithm took 0.14143991470336914\n"
     ]
    }
   ],
   "source": [
    "r = list(map(int,(np.loadtxt(\"input_files/RECORDS\"))))\n",
    "records = list(map(str,r))\n",
    "FILE_SAVE=True\n",
    "\n",
    "if FILE_SAVE:\n",
    "    import time\n",
    "    t1 = time.time()\n",
    "    \n",
    "    # we want to save a dataframe of heartbeats: to do that, I initialize some temporary means of storage\n",
    "    # - the number that identifies the patient\n",
    "    number = np.array([0])\n",
    "    # - the number that identifies the heartbeat of each patient\n",
    "    idx = np.array([0])\n",
    "    # - the index of the start of the heartbeat\n",
    "    start = np.array([0])\n",
    "    # - the index of the end of the heartbeat\n",
    "    end = np.array([0]) \n",
    "    # - the index of the R peak of the heartbeat\n",
    "    R_peak = np.array([0]) \n",
    "    # - the symbol for the annotation of the heartbeat\n",
    "    annot = [None] \n",
    "    \n",
    "    # I then fill such temporary means of storage by updating them after analyzing every file/patient\n",
    "    for path in records:\n",
    "        # UPLOAD\n",
    "        # data = pd.read_csv(\"output_files/data\"+path+\".csv\")\n",
    "        annotations = pd.read_csv(\"output_files/data\"+path+\"_ann.csv\")\n",
    "        ann = np.array(annotations['index'])\n",
    "        \n",
    "        # and use my custom function for SEGMENTATION\n",
    "        QT_size, PR_size, patient_start, patient_end, i, j = segmentation(ann)\n",
    "        # I add the remaining pieces of information\n",
    "        # - the number of the patient is the same for all its heartbeats\n",
    "        patient_number = np.ones_like(patient_start)*int(path)\n",
    "        # - the number that identifies the heartbeat of each patient is a simple increasing vector of integers\n",
    "        patient_idx = np.arange(0,len(patient_start),1,dtype = int)\n",
    "        # - the location of the R peaks (by cropping the annotations accordingly)\n",
    "        patient_R_peak = ann[j:-i]\n",
    "        # - the symbols for the annotations (by cropping the annotations accordingly)\n",
    "        patient_ann = list(annotations['symbol'][j:-i])\n",
    "        \n",
    "        # lastly, I check that all the annotations are in between the corresponding starts and stops\n",
    "        check = np.all([(patient_R_peak>patient_start),(patient_R_peak<patient_end)])\n",
    "        if not check:\n",
    "            print(check)\n",
    "           \n",
    "        # and update the temporary means of storage\n",
    "        number = np.concatenate((number, patient_number))\n",
    "        idx = np.concatenate((idx, patient_idx))\n",
    "        start = np.concatenate((start, patient_start))\n",
    "        end = np.concatenate((end, patient_end))\n",
    "        R_peak = np.concatenate((R_peak, patient_R_peak))\n",
    "        annot.extend(patient_ann)\n",
    "    \n",
    "    # finally, I put together the heartbeat dataframe  \n",
    "    hb = pd.DataFrame({\"patient\": number[1:], \"label\": idx[1:], \"start\": start[1:], \"end\": end[1:],\n",
    "                       \"R_peak\": R_peak[1:], \"ann\": annot[1:] })\n",
    "    t2 = time.time()\n",
    "    print(\"the algorithm took\",t2-t1)\n",
    "    outfn = 'output_files/heartbeats.csv'\n",
    "    hb.to_csv(outfn, index=False)\n",
    "else:\n",
    "    hb = pd.read_csv('output_files/heartbeats.csv')\n",
    "    \n",
    "    display(hb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa289bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
